{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MORE NODES\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(128, 128, 1)) \n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "sr_encoder = Model(input_img, decoded)\n",
    "sr_encoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LESS NODES\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "#input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "input_img = Input(shape=(128, 128, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x) # EB DEBUGGED!!\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "sr_encoder = Model(input_img, decoded)\n",
    "sr_encoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAILSAFE\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "#input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "input_img = Input(shape=(128, 128, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "enc = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "enc = MaxPooling2D((2, 2), padding='same')(enc) # padding same required here\n",
    "#enc = Conv2D(16, (3, 3), activation='relu')(input_img)\n",
    "\n",
    "#encoded = MaxPooling2D((2, 2), padding='same')(enc)\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "dec = UpSampling2D((2, 2))(enc)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(dec)\n",
    "#decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(enc)\n",
    "#x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "#decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "sr_encoder = Model(input_img, decoded)\n",
    "sr_encoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIG FROM TUTORIAL\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x) # EB DEBUGGED!!\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_IND = 169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirstr = '/home/ericbarnhill/Documents/MATLAB/ericbarnhill/projects/2017-11-21-ml-7t/'\n",
    "os.chdir(dirstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_slices = sio.loadmat(file_name='slices.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_1_5t = matlab_slices['slices_1_5t']\n",
    "slices_3t = matlab_slices['slices_3t']\n",
    "slices_7t = matlab_slices['slices_7t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_slices['slices_3t'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_1_5t = slices_1_5t.astype(np.float32)\n",
    "slices_3t = slices_3t.astype(np.float32)\n",
    "slices_7t = slices_7t.astype(np.float32)\n",
    "slices_1_5t[np.isnan(slices_1_5t)] = 0\n",
    "slices_3t[np.isnan(slices_3t)] = 0\n",
    "slices_7t[np.isnan(slices_7t)] = 0\n",
    "slices_1_5t = slices_1_5t[:,:,0:221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_clip_neg(array):\n",
    "    array[array < 0] = 0;\n",
    "    mn = np.min(array)\n",
    "    mx = np.max(array)\n",
    "    print(mn)\n",
    "    print(mx)\n",
    "    array = (array - mn) / mx - mn\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_1_5t = normalize_clip_neg(slices_1_5t)\n",
    "slices_3t = normalize_clip_neg(slices_3t)\n",
    "slices_7t = normalize_clip_neg(slices_7t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slices_1_5t.dtype)\n",
    "print(np.min(slices_3t))\n",
    "print(np.max(slices_7t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sr_data(data):\n",
    "    shp = data.shape\n",
    "    data = np.moveaxis(data, [0,1,2], [-2,-1,-3])\n",
    "    data = data.reshape((shp[2], shp[0], shp[1], 1))\n",
    "    data_pad = np.zeros((shp[2], 128, 128, 1))\n",
    "    data_pad[:, 0:87, 0:101, :] = data\n",
    "    return data_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "train_1_5t = slices_1_5t[:,:,:SPLIT_IND]\n",
    "train_3t = slices_3t[:,:,:SPLIT_IND]\n",
    "train_7t = slices_7t[:,:,:SPLIT_IND]\n",
    "test_1_5t = slices_1_5t[:,:,SPLIT_IND::]\n",
    "test_3t = slices_3t[:,:,SPLIT_IND::]\n",
    "test_7t = slices_7t[:,:,SPLIT_IND::]\n",
    "in_dat = prepare_sr_data(np.concatenate((train_1_5t, train_3t), 2))\n",
    "out_dat = prepare_sr_data(np.concatenate((train_7t, train_7t), 2))\n",
    "test_dat = prepare_sr_data(np.concatenate((test_1_5t, test_3t), 2))\n",
    "\n",
    "print(test_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_1_5t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.moveaxis(test_1_5t, [0, 1, 2], [-2, -1, -3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with 7T labels\n",
    "sr_encoder.fit(in_pad, out_pad,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_split=0.3,\n",
    "                callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 236 samples, validate on 102 samples\n",
      "Epoch 1/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1959 - val_loss: 0.1777\n",
      "Epoch 2/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1951 - val_loss: 0.1771\n",
      "Epoch 3/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1946 - val_loss: 0.1769\n",
      "Epoch 4/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1943 - val_loss: 0.1767\n",
      "Epoch 5/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1939 - val_loss: 0.1760\n",
      "Epoch 6/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1937 - val_loss: 0.1760\n",
      "Epoch 7/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1934 - val_loss: 0.1760\n",
      "Epoch 8/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1932 - val_loss: 0.1755\n",
      "Epoch 9/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1929 - val_loss: 0.1752\n",
      "Epoch 10/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1926 - val_loss: 0.1749\n",
      "Epoch 11/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1923 - val_loss: 0.1748\n",
      "Epoch 12/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1921 - val_loss: 0.1749\n",
      "Epoch 13/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1919 - val_loss: 0.1742\n",
      "Epoch 14/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1916 - val_loss: 0.1744\n",
      "Epoch 15/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1914 - val_loss: 0.1737\n",
      "Epoch 16/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1912 - val_loss: 0.1733\n",
      "Epoch 17/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1910 - val_loss: 0.1734\n",
      "Epoch 18/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1908 - val_loss: 0.1732\n",
      "Epoch 19/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1905 - val_loss: 0.1731\n",
      "Epoch 20/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1903 - val_loss: 0.1728\n",
      "Epoch 21/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1901 - val_loss: 0.1729\n",
      "Epoch 22/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1898 - val_loss: 0.1722\n",
      "Epoch 23/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1896 - val_loss: 0.1721\n",
      "Epoch 24/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1893 - val_loss: 0.1720\n",
      "Epoch 25/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1891 - val_loss: 0.1723\n",
      "Epoch 26/50\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.1890 - val_loss: 0.1723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb928fde668>"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autoencode\n",
    "sr_encoder.fit(in_pad, in_pad,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_split=0.3,\n",
    "                callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = sr_encoder.predict(test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat(mdict={'pred_img':pred_img}, file_name=\"pred_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = encoder.predict(test_dat)\n",
    "sio.savemat(mdict={'filts':filts}, file_name=\"filts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x7fb94dacf860>\n"
     ]
    }
   ],
   "source": [
    "l = sr_encoder.layers[1]\n",
    "l.get_weights()\n",
    "sio.savemat(mdict={'weights1':l.get_weights()}, file_name=\"weights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat(mdict={'in_dat':in_dat}, file_name=\"in_dat.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x_train.dtype)\n",
    "print(x.dtype)\n",
    "print(y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, enc)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = sr_encoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(64), Dimension(64), Dimension(8)])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sr_encoder.layers[3]\n",
    "b = a.output\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "layer_dict = dict([(layer.name, layer) for layer in sr_encoder.layers])\n",
    "filter_index = 3;\n",
    "layer_name = \"conv2d_162\"\n",
    "layer_output = layer_dict[layer_name].output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "img_height = 128;\n",
    "img_width = 128;\n",
    "input_img_data = np.random.random((1, img_width, img_height, 1)) * 20 + 128\n",
    "input_img_data.shape\n",
    "step = 0.1\n",
    "for i in range(20):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_161/Relu:0\", shape=(?, 128, 128, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "img_sq = np.squeeze(img)\n",
    "print(img_sq.shape)\n",
    "imsave('%s_filter_%d.png' % (layer_name, filter_index), img_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'arr' does not have a suitable array shape for any mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-368-15dd71ad00ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_img_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s_filter_%d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(name, arr, format)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mtoimage\u001b[0;34m(arr, high, low, cmin, cmax, pal, mode, channel_axis)\u001b[0m\n\u001b[1;32m    285\u001b[0m                                 ((3 in shape) or (4 in shape)))\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         raise ValueError(\"'arr' does not have a suitable array shape for \"\n\u001b[0m\u001b[1;32m    288\u001b[0m                          \"any mode.\")\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'arr' does not have a suitable array shape for any mode."
     ]
    }
   ],
   "source": [
    "from scipy.misc import imsave\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "img = input_img_data[0]\n",
    "img = deprocess_image(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
